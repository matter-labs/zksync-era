use std::sync::Arc;

use anyhow::Context as _;
use zksync_concurrency::{ctx, error::Wrap as _, scope};
use zksync_config::configs::consensus::{ConsensusConfig, ConsensusSecrets};
use zksync_consensus_engine::EngineManager;
use zksync_consensus_executor::{self as executor};
use zksync_node_sync::ActionQueueSender;
use zksync_shared_resources::api::SyncState;
use zksync_state_keeper::StateKeeper;
use crate::{
    config,
    registry::{Registry, RegistryAddress},
    storage::{ConnectionPool, Store},
};

/// Task running a consensus validator for the main node.
/// Main node is currently the only leader of the consensus - i.e. it proposes all the
/// L2 blocks (generated by `Statekeeper`).
pub async fn run_main_node(
    ctx: &ctx::Ctx,
    cfg: ConsensusConfig,
    secrets: ConsensusSecrets,
    pool: ConnectionPool,
    sk: Option<StateKeeper>,
    actions_and_sync_state: Option<(ActionQueueSender, SyncState)>,
) -> anyhow::Result<()> {
    let res: ctx::Result<()> = scope::run!(&ctx, |ctx, s| async {
        if let Some(spec) = &cfg.genesis_spec {
            let spec = config::GenesisSpec::parse(spec).context("GenesisSpec::parse()")?;

            pool.connection(ctx)
                .await
                .wrap("connection()")?
                .adjust_global_config(ctx, &spec)
                .await
                .wrap("adjust_global_config()")?;
        }

        // Initialize global config.
        let global_config = pool
            .connection(ctx)
            .await
            .wrap("connection()")?
            .global_config(ctx)
            .await
            .wrap("global_config()")?
            .context("global_config() disappeared")?;

        // Initialize registry.
        let registry = Arc::new(match global_config.registry_address {
            Some(addr) => Some(Registry::new(pool.clone(), RegistryAddress::new(addr)).await),
            None => None,
        });


        let payload_queue = if let Some((actions, sync_state)) = actions_and_sync_state {
            let payload_queue = pool.connection(ctx)
                .await
                .wrap("connection()")?
                .new_payload_queue(ctx, actions, sync_state)
                .await
                .wrap("new_payload_queue()")?;
            Some(payload_queue)
        } else {
            None
        };

        // The main node doesn't have a payload queue as it produces all the L2 blocks itself.
        let (store, runner) = Store::new(ctx, pool.clone(), payload_queue, None, registry.clone(), sk)
            .await
            .wrap("Store::new()")?;
        s.spawn_bg(async { Ok(runner.run(ctx).await.context("Store::runner()")?) });

        let (engine_manager, engine_runner) = EngineManager::new(ctx, Box::new(store.clone()))
            .await
            .wrap("BlockStore::new()")?;
        s.spawn_bg(async { Ok(engine_runner.run(ctx).await.context("BlockStore::run()")?) });

        let executor = executor::Executor {
            config: config::executor(&cfg, &secrets, &global_config, None)?,
            engine_manager,
        };

        tracing::info!("running the main node executor");
        executor.run(ctx).await.context("main node executor")?;
        Ok(())
    })
    .await;

    match res {
        Ok(()) | Err(ctx::Error::Canceled(_)) => Ok(()),
        Err(ctx::Error::Internal(err)) => Err(err),
    }
}
